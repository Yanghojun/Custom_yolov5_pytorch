{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문장 평가\n",
    "- [잘 설명해준 사이트](https://jrc-park.tistory.com/273)\n",
    "- 생성된 문장을 평가하는 방식은 크게 2가지 (Reference가 Ground truth로 보면 되는 듯)\n",
    "  1. Rouge: Reference 문장의 단어가 Generated 문장에 포함되는 정도\n",
    "     - Text Summarization\n",
    "  2. **BLEU**: Generated 문장의 단어가 Reference Sentence에 포함되는 정도\n",
    "     - Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 코드 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [[\"this\", \"is\", \"the\", \"sample\"]]\n",
    "candidate = ['this', \"is\", \"the\", \"sample\"]\n",
    "score1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0)) # 1.0\n",
    "\n",
    "score1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram\n",
    "- 위 sentence_bleu 함수의 weights 인자에 들어가는것이 N-gram 인자이며 (1, 0, 0, 0)은 1-gram token들로만 평가를 진행한다는 의미\n",
    "  - 1-gram\n",
    "    - this, is, the, sample\n",
    "  - 2-gram\n",
    "    - this is, is the, the sample\n",
    "  - 3-gram\n",
    "    - this is the, is the sample\n",
    "  - 4-gram\n",
    "    - this is the sample\n",
    "- gram 수가 올라갈수록 **순서를 정확히 고려**해야 하므로 높은 점수를 받기가 쉽지 않아짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram score: 1.0, 2-gram score: 0.3333333333333333, 2-gram_v2 score: 2.2250738585072626e-308\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "reference = [[\"나는\", \"너를\", \"사랑해\", \"정말로\"]]\n",
    "candidate = [\"나는\", \"사랑해\", \"정말로\", \"너를\"]\n",
    "candidate_v2 = [\"나는\", \"사랑해\", \"너를\", \"정말로\"]\n",
    "gram1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "gram2 = sentence_bleu(reference, candidate, weights=(0, 1, 0, 0))\n",
    "gram_v2 = sentence_bleu(reference, candidate_v2, weights=(0, 1, 0, 0)) # 1.0\n",
    "\n",
    "print(f'1-gram score: {gram1}, 2-gram score: {gram2}, 2-gram_v2 score: {gram_v2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2-gram의 경우 \"사랑해\", \"정말로\" 를 통해 2-gram 에 포함되어 있는 문장을 맞췄지만 2-gram_v2의 경우에는 그렇지 못해서 0 값(표기상으론 아주 작은값)을 받은 걸 알 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47f8095db4e88d9324e13ce1300914effea698f100add04b6f2216b38806a641"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('yolov5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
